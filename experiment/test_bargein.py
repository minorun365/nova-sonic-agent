"""å‰²ã‚Šè¾¼ã¿ï¼ˆbarge-inï¼‰ãƒ†ã‚¹ãƒˆã€‚

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒé•·ã„å¿œç­”ã‚’ç”Ÿæˆä¸­ã«ã€é€”ä¸­ã§æ–°ã—ã„éŸ³å£°ã‚’é€ä¿¡ã—ã€
BidiInterruptionEvent ãŒç™ºç”Ÿã™ã‚‹ã‹ç¢ºèªã™ã‚‹ã€‚

ä½¿ã„æ–¹:
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’äº‹å‰ã«ç”Ÿæˆ
    say -v Kyoko -o /tmp/test_long.aiff "æ—¥æœ¬ã®éƒ½é“åºœçœŒã‚’åŒ—ã‹ã‚‰é †ã«å…¨éƒ¨æ•™ãˆã¦ãã ã•ã„"
    ffmpeg -y -i /tmp/test_long.aiff -f s16le -acodec pcm_s16le -ar 16000 -ac 1 /tmp/test_long.pcm

    say -v Kyoko -o /tmp/test_interrupt.aiff "ã‚¹ãƒˆãƒƒãƒ—ã€ã‚„ã‚ã¦ãã ã•ã„"
    ffmpeg -y -i /tmp/test_interrupt.aiff -f s16le -acodec pcm_s16le -ar 16000 -ac 1 /tmp/test_interrupt.pcm

    python test_bargein.py
"""

import asyncio
import base64
import time

import boto3
from strands.experimental.bidi import BidiAgent
from strands.experimental.bidi.models.nova_sonic import BidiNovaSonicModel
from strands.experimental.bidi.tools import stop_conversation
from strands.experimental.bidi.types.events import (
    BidiAudioInputEvent,
    BidiAudioStreamEvent,
    BidiOutputEvent,
    BidiTranscriptStreamEvent,
)

SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_MS = 20
CHUNK_SIZE = SAMPLE_RATE * 2 * CHUNK_MS // 1000


class BargeInAudioInput:
    """æœ€åˆã®è³ªå•ã‚’é€ã‚Šã€å¿œç­”ãŒå§‹ã¾ã£ãŸã‚‰å‰²ã‚Šè¾¼ã¿éŸ³å£°ã‚’é€ä¿¡ã™ã‚‹ã€‚"""

    def __init__(self, question_pcm: str, interrupt_pcm: str, output_handler: "BargeInOutput") -> None:
        # è³ªå•éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        with open(question_pcm, "rb") as f:
            raw = f.read()
        self._question_chunks = [raw[i : i + CHUNK_SIZE] for i in range(0, len(raw), CHUNK_SIZE)]
        q_duration = len(raw) / (SAMPLE_RATE * 2) * 1000
        print(f"  è³ªå•éŸ³å£°: {q_duration:.0f}ms ({len(raw)} bytes)")

        # è³ªå•å¾Œã®ç„¡éŸ³ï¼ˆVAD ãƒˆãƒªã‚¬ãƒ¼ï¼‰
        silence = b"\x00" * CHUNK_SIZE
        self._silence_chunks = [silence] * (3000 // CHUNK_MS)

        # å‰²ã‚Šè¾¼ã¿éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        with open(interrupt_pcm, "rb") as f:
            raw2 = f.read()
        self._interrupt_chunks = [raw2[i : i + CHUNK_SIZE] for i in range(0, len(raw2), CHUNK_SIZE)]
        i_duration = len(raw2) / (SAMPLE_RATE * 2) * 1000
        print(f"  å‰²ã‚Šè¾¼ã¿éŸ³å£°: {i_duration:.0f}ms ({len(raw2)} bytes)")

        # å‰²ã‚Šè¾¼ã¿å¾Œã®ç„¡éŸ³
        self._interrupt_silence = [silence] * (3000 // CHUNK_MS)

        self._output = output_handler
        self._phase = "question"  # question â†’ silence â†’ wait â†’ interrupt â†’ interrupt_silence â†’ done
        self._index = 0
        self._interrupt_sent = False

    async def __call__(self) -> BidiAudioInputEvent:
        chunk = None

        if self._phase == "question":
            if self._index < len(self._question_chunks):
                chunk = self._question_chunks[self._index]
                self._index += 1
            else:
                self._phase = "silence"
                self._index = 0
                print("  [å…¥åŠ›] è³ªå•é€ä¿¡å®Œäº† â†’ ç„¡éŸ³é€ä¿¡ï¼ˆVADãƒˆãƒªã‚¬ãƒ¼ï¼‰")

        if self._phase == "silence":
            if self._index < len(self._silence_chunks):
                chunk = self._silence_chunks[self._index]
                self._index += 1
            else:
                self._phase = "wait"
                self._index = 0
                print("  [å…¥åŠ›] ç„¡éŸ³å®Œäº† â†’ å¿œç­”å¾…ã¡...")

        if self._phase == "wait":
            # å¿œç­”ã®éŸ³å£°å‡ºåŠ›ãŒå§‹ã¾ã£ãŸã‚‰å‰²ã‚Šè¾¼ã¿ã‚’é–‹å§‹
            if self._output.audio_event_count >= 5:
                self._phase = "interrupt"
                self._index = 0
                print("  ğŸ¤ [å‰²ã‚Šè¾¼ã¿é–‹å§‹] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”ä¸­ã«å‰²ã‚Šè¾¼ã¿éŸ³å£°ã‚’é€ä¿¡ï¼")

        if self._phase == "interrupt":
            if self._index < len(self._interrupt_chunks):
                chunk = self._interrupt_chunks[self._index]
                self._index += 1
                if self._index == len(self._interrupt_chunks):
                    self._interrupt_sent = True
            else:
                self._phase = "interrupt_silence"
                self._index = 0
                print("  [å…¥åŠ›] å‰²ã‚Šè¾¼ã¿éŸ³å£°é€ä¿¡å®Œäº† â†’ ç„¡éŸ³é€ä¿¡")

        if self._phase == "interrupt_silence":
            if self._index < len(self._interrupt_silence):
                chunk = self._interrupt_silence[self._index]
                self._index += 1
            else:
                self._phase = "done"

        if chunk is None:
            chunk = b"\x00" * CHUNK_SIZE

        await asyncio.sleep(CHUNK_MS / 1000)
        audio_b64 = base64.b64encode(chunk).decode("ascii")
        return BidiAudioInputEvent(audio=audio_b64, format="pcm", sample_rate=SAMPLE_RATE, channels=CHANNELS)

    async def start(self, agent) -> None:
        pass

    async def stop(self) -> None:
        pass


class BargeInOutput:
    """å‰²ã‚Šè¾¼ã¿ã‚¤ãƒ™ãƒ³ãƒˆã«æ³¨ç›®ã—ãŸå‡ºåŠ›ãƒãƒ³ãƒ‰ãƒ©ã€‚"""

    def __init__(self) -> None:
        self.events: list[str] = []
        self.audio_event_count = 0
        self.interruption_detected = False
        self.transcript_parts: list[str] = []
        self._response_count = 0

    async def __call__(self, event: BidiOutputEvent) -> None:
        event_type = type(event).__name__

        if isinstance(event, BidiTranscriptStreamEvent):
            role = getattr(event, "role", "?")
            text = getattr(event, "text", "")
            is_final = getattr(event, "is_final", False)
            if is_final:
                print(f"  [ç¢ºå®š] ({role}): {text}")
                self.transcript_parts.append(f"({role}): {text}")
            else:
                # é€”ä¸­ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯é•·ããªã‚‹ã®ã§å…ˆé ­ã ã‘
                if len(text) < 80:
                    print(f"  [é€”ä¸­] ({role}): {text}")
        elif isinstance(event, BidiAudioStreamEvent):
            self.audio_event_count += 1
            if self.audio_event_count <= 3:
                print(f"  [éŸ³å£°å‡ºåŠ›] chunk #{self.audio_event_count}")
            elif self.audio_event_count == 4:
                print(f"  [éŸ³å£°å‡ºåŠ›] ... (ä»¥é™çœç•¥)")
        elif "Interruption" in event_type:
            self.interruption_detected = True
            print(f"  âš¡ [å‰²ã‚Šè¾¼ã¿æ¤œå‡º!] {event_type}: {event}")
        elif "ResponseStart" in event_type:
            self._response_count += 1
            print(f"  [ResponseStart #{self._response_count}]")
        elif "ResponseComplete" in event_type:
            print(f"  [ResponseComplete]")
        elif "Error" in event_type:
            print(f"  âŒ [{event_type}] {event}")
        elif "Connection" in event_type:
            print(f"  [{event_type}]")

        self.events.append(event_type)

    async def start(self, agent) -> None:
        pass

    async def stop(self) -> None:
        pass


async def main() -> None:
    print("=" * 60)
    print("å‰²ã‚Šè¾¼ã¿ï¼ˆbarge-inï¼‰ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print("ã‚·ãƒŠãƒªã‚ª: é•·ã„è³ªå•â†’å¿œç­”é–‹å§‹å¾Œã«å‰²ã‚Šè¾¼ã¿éŸ³å£°ã‚’é€ä¿¡")
    print()

    session = boto3.Session(profile_name="sandbox", region_name="us-east-1")

    model = BidiNovaSonicModel(
        model_id="amazon.nova-sonic-v1:0",
        provider_config={
            "audio": {
                "input_sample_rate": SAMPLE_RATE,
                "output_sample_rate": SAMPLE_RATE,
                "voice": "tiffany",
            },
        },
        client_config={
            "boto_session": session,
        },
    )

    agent = BidiAgent(
        model=model,
        tools=[stop_conversation],
        system_prompt="ã‚ãªãŸã¯æ—¥æœ¬èªã®éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚è³ªå•ã«ã¯ä¸å¯§ã«è©³ã—ãç­”ãˆã¦ãã ã•ã„ã€‚",
    )

    output_handler = BargeInOutput()
    audio_input = BargeInAudioInput(
        question_pcm="/tmp/test_long.pcm",
        interrupt_pcm="/tmp/test_interrupt.pcm",
        output_handler=output_handler,
    )

    print("-" * 60)

    try:
        await asyncio.wait_for(
            agent.run(inputs=[audio_input], outputs=[output_handler]),
            timeout=45,
        )
    except asyncio.TimeoutError:
        print("\n  --- 45ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ---")

    print()
    print("=" * 60)
    print("ãƒ†ã‚¹ãƒˆçµæœ")
    print("=" * 60)
    print(f"  å‰²ã‚Šè¾¼ã¿æ¤œå‡º (BidiInterruptionEvent): {'âœ… ã‚ã‚Š' if output_handler.interruption_detected else 'âŒ ãªã—'}")
    print(f"  å—ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(output_handler.events)}")
    print(f"  éŸ³å£°å‡ºåŠ›ãƒãƒ£ãƒ³ã‚¯æ•°: {output_handler.audio_event_count}")
    event_types = set(output_handler.events)
    print(f"  ã‚¤ãƒ™ãƒ³ãƒˆç¨®é¡: {event_types}")
    if output_handler.transcript_parts:
        print(f"  ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:")
        for t in output_handler.transcript_parts:
            print(f"    â†’ {t}")


if __name__ == "__main__":
    asyncio.run(main())
