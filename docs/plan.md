まず今からやりたいことは音声で会話できるAIエージェントのデモアプリを作りたいです。技術としては全てAWSの最新機能を使いたく、Strands AgentsとBedrock AgentCoreを使って、SOHOに用意されているByEAgentというクラス情報を基に、情報通信のためのストリーミング機能を使って、Amazon Novaの音声対応モデル、特にNovaSonicを使って、ユーザーとエージェントが音声で会話しながらツールを使ったりできるエージェントを作りたいです。

ただ、StrandsとAgentCoreでNovaSonicを使って音声で対話するというのはいきなりでは、アンプリファイとか使ったり、Cloud Agent Core上にデプロイして動作確認すると、最初はバグが多くて大変になる可能性があります。もし必要であれば、Experiment Directoryの下にシンプルなStrandsとNovaSonicを使った音声エージェントを作って、まずはCLIベースで、もしくは簡単なフロントエンドだけをローカル起動前提でつけて、音声対話エージェントの簡単なフィジビリティが取れた上で、本格的な実装に進むっていう方がいいんじゃないかなと思ったりしてます。

この辺りについて必要な最新情報を徹底調査した上で、このプロジェクトの進め方などをspec.mdというマークダウンを作って、そこに書き出してもらえますか？もし私に詳細を確認すべきことなどがあれば、聞いてください。あと、AmplifyとAgentCoreとCDKを使ったデモアプリは、私はこれまでたくさん作ってますので、必要があれば以下のプロジェクトを参考に、実装のベースを固めてください。

https://github.com/minorun365/marp-agent